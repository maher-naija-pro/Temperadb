name: Performance Regression Detection

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
  # Run performance regression detection on schedule (daily at 3 AM UTC)
  schedule:
    - cron: '0 3 * * *'
  # Allow manual triggering
  workflow_dispatch:

jobs:
  performance-regression:
    runs-on: ubuntu-latest
    permissions:
      issues: write
      pull-requests: write
      contents: read
    
    strategy:
      matrix:
        go-version: ['1.22']  # Use latest stable Go version for regression detection
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Go ${{ matrix.go-version }}
      uses: actions/setup-go@v4
      with:
        go-version: ${{ matrix.go-version }}
        
    - name: Init go.mod if missing
      run: |
        if [ ! -f "go.mod" ]; then
          echo "go.mod not found, initializing for current project..."
          go mod init timeseriesdb
        else
          echo "go.mod already exists."
        fi

    - name: Download dependencies
      run: go mod tidy
      
    - name: Verify dependencies
      run: go mod verify
      
    - name: Run benchmarks for current commit
      run: |
        echo "Running benchmarks for performance regression detection..."
        # Ensure benchmark-results directory exists
        mkdir -p benchmark-results
        ./scripts/run-benchmarks.sh -a -o "benchmark_current_${{ github.sha }}.txt"
      working-directory: .
      
    - name: Check if baseline exists
      id: check-baseline
      run: |
        # Ensure benchmark-results directory exists
        mkdir -p benchmark-results
        if [ -f "benchmark-results/baseline.txt" ]; then
          echo "baseline-exists=true" >> $GITHUB_OUTPUT
        else
          echo "baseline-exists=false" >> $GITHUB_OUTPUT
        fi
      working-directory: .
      
    - name: Set baseline if not exists
      if: steps.check-baseline.outputs.baseline-exists == 'false'
      run: |
        echo "No baseline found, setting current results as baseline..."
        # Ensure benchmark-results directory exists
        mkdir -p benchmark-results
        ./scripts/run-benchmarks.sh -b -o "benchmark_current_${{ github.sha }}.txt"
      working-directory: .
      
    - name: Detect performance regressions
      if: steps.check-baseline.outputs.baseline-exists == 'true'
      id: regression-check
      run: |
        echo "Running performance regression detection..."
        # Ensure benchmark-results directory exists
        mkdir -p benchmark-results
        ./scripts/detect-regressions.sh \
          -c "benchmark-results/benchmark_current_${{ github.sha }}.txt" \
          -t 5.0 \
          --critical-threshold 15.0 \
          -H \
          -j
      working-directory: .
      continue-on-error: true
      
    - name: Check if regression reports exist
      if: always() && steps.check-baseline.outputs.baseline-exists == 'true'
      run: |
        echo "Checking if regression reports exist..."
        if ls benchmark-results/regression_report_* 1> /dev/null 2>&1; then
          echo "Regression reports found, will upload artifacts"
          echo "reports-exist=true" >> $GITHUB_OUTPUT
        else
          echo "No regression reports found, skipping artifact upload"
          echo "reports-exist=false" >> $GITHUB_OUTPUT
        fi
      working-directory: .
      
    - name: Upload regression reports
      if: always() && steps.check-baseline.outputs.baseline-exists == 'true' && steps.check-regression-reports.outputs.reports-exist == 'true'
      uses: actions/upload-artifact@v4
      with:
        name: performance-regression-reports-${{ matrix.go-version }}
        path: |
          benchmark-results/regression_report_*.txt
          benchmark-results/regression_report_*.html
          benchmark-results/regression_report_*.json
        retention-days: 90
        
    - name: Comment on PR with regression summary
      if: github.event_name == 'pull_request' && steps.check-baseline.outputs.baseline-exists == 'true'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const path = require('path');
          
          try {
            // Find the latest regression report
            const resultsDir = 'benchmark-results';
            const files = fs.readdirSync(resultsDir);
            const regressionFiles = files.filter(f => f.startsWith('regression_report_') && f.endsWith('.txt'));
            
            if (regressionFiles.length === 0) {
              console.log('No regression reports found');
              return;
            }
            
            // Sort by timestamp and get the latest
            regressionFiles.sort().reverse();
            const latestReport = regressionFiles[0];
            const reportPath = path.join(resultsDir, latestReport);
            
            const reportContent = fs.readFileSync(reportPath, 'utf8');
            
            // Extract summary information
            const summaryMatch = reportContent.match(/Total benchmarks analyzed: (\d+)/);
            const regressionMatch = reportContent.match(/Performance regressions: (\d+)/);
            const criticalMatch = reportContent.match(/Critical regressions: (\d+)/);
            const improvementMatch = reportContent.match(/Performance improvements: (\d+)/);
            
            const total = summaryMatch ? summaryMatch[1] : '0';
            const regressions = regressionMatch ? regressionMatch[1] : '0';
            const critical = criticalMatch ? criticalMatch[1] : '0';
            const improvements = improvementMatch ? improvementMatch[1] : '0';
            
            let status = 'âœ…';
            let statusText = 'No performance regressions detected';
            
            if (critical > 0) {
              status = 'ðŸš¨';
              statusText = `Critical performance regressions detected: ${critical}`;
            } else if (regressions > 0) {
              status = 'âš ï¸';
              statusText = `Performance regressions detected: ${regressions}`;
            }
            
            const comment = `## ${status} Performance Regression Detection Results
            
            **Status:** ${statusText}
            
            **Summary:**
            - Total benchmarks analyzed: ${total}
            - Performance regressions: ${regressions}
            - Critical regressions: ${critical}
            - Performance improvements: ${improvements}
            
            **Details:** Full regression report is available in the workflow artifacts.
            
            **Thresholds:** 5% for warnings, 15% for critical regressions.
            
            ${regressions > 0 || critical > 0 ? '**âš ï¸ Please review these performance changes before merging.**' : ''}`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
            
          } catch (error) {
            console.log('Could not read regression report:', error.message);
          }
          
    - name: Fail workflow on critical regressions
      if: steps.regression-check.outcome == 'failure' && steps.regression-check.exit-code == 2
      run: |
        echo "ðŸš¨ Critical performance regressions detected!"
        echo "Workflow will fail to prevent merging of performance-degrading code."
        exit 1
      working-directory: .
      
    - name: Check if benchmark file exists
      if: always()
      run: |
        echo "Checking if benchmark file exists..."
        if [ -f "benchmark-results/benchmark_current_${{ github.sha }}.txt" ]; then
          echo "Benchmark file exists, will upload artifact"
          echo "file-exists=true" >> $GITHUB_OUTPUT
        else
          echo "Benchmark file does not exist, skipping artifact upload"
          echo "file-exists=false" >> $GITHUB_OUTPUT
        fi
      working-directory: .
      
    - name: Upload benchmark results
      if: always() && steps.check-benchmark-file.outputs.file-exists == 'true'
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results-${{ matrix.go-version }}
        path: |
          benchmark-results/benchmark_current_${{ github.sha }}.txt
        retention-days: 30
        
    - name: Clean up temporary files
      if: always()
      run: |
        echo "Cleaning up temporary files..."
        # Ensure benchmark-results directory exists before cleanup
        mkdir -p benchmark-results
        rm -f benchmark-results/benchmark_current_${{ github.sha }}.txt
      working-directory: .

  performance-trends:
    runs-on: ubuntu-latest
    needs: performance-regression
    if: always()
    permissions:
      contents: read
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: '1.22'
        
    - name: Check dependency job status
      run: |
        echo "Performance regression job status: ${{ needs.performance-regression.result }}"
        echo "Performance regression job conclusion: ${{ needs.performance-regression.conclusion }}"
        
        if [ "${{ needs.performance-regression.result }}" != "success" ]; then
          echo "Warning: Performance regression job did not complete successfully"
          echo "This may affect the availability of benchmark artifacts"
        fi
        
    - name: Download benchmark artifacts
      uses: actions/download-artifact@v4
      with:
        name: benchmark-results-1.22
        path: benchmark-results/
      continue-on-error: true
        
    - name: Generate performance trends report
      run: |
        echo "Generating performance trends report..."
        
        # Check if benchmark artifacts were downloaded
        if [ ! -d "benchmark-results" ] || [ -z "$(ls -A benchmark-results 2>/dev/null)" ]; then
          echo "No benchmark artifacts found. Creating empty trends report."
          echo "=== Performance Trends Summary ===" > trends_report.txt
          echo "Generated: $(date)" >> trends_report.txt
          echo "" >> trends_report.txt
          echo "No benchmark data available for trends analysis." >> trends_report.txt
          echo "This may happen if:" >> trends_report.txt
          echo "- The performance regression job failed" >> trends_report.txt
          echo "- No artifacts were uploaded" >> trends_report.txt
          echo "- Artifacts have expired" >> trends_report.txt
          echo "" >> trends_report.txt
          echo "Job Status: ${{ needs.performance-regression.result }}" >> trends_report.txt
          echo "Job Conclusion: ${{ needs.performance-regression.conclusion }}" >> trends_report.txt
          exit 0
        fi
        
        # Create a simple trends summary
        echo "=== Performance Trends Summary ===" > trends_report.txt
        echo "Generated: $(date)" >> trends_report.txt
        echo "" >> trends_report.txt
        
        # Count total benchmark runs
        total_runs=$(ls benchmark-results/benchmark_*.txt 2>/dev/null | wc -l)
        echo "Total benchmark runs: $total_runs" >> trends_report.txt
        
        if [ $total_runs -eq 0 ]; then
          echo "No benchmark files found in the artifacts." >> trends_report.txt
          echo "This suggests the benchmark step may have failed or the file was not created." >> trends_report.txt
        else
          # Find the most recent results
          latest_file=$(ls -t benchmark-results/benchmark_*.txt 2>/dev/null | head -1)
          if [ -n "$latest_file" ]; then
            echo "Latest benchmark run: $latest_file" >> trends_report.txt
            
            # Extract some key metrics
            echo "" >> trends_report.txt
            echo "Latest benchmark results summary:" >> trends_report.txt
            echo "--------------------------------" >> trends_report.txt
            
            # Show first few benchmark results
            head -20 "$latest_file" >> trends_report.txt
          fi
        fi
        
        echo "" >> trends_report.txt
        echo "For detailed analysis, check the regression detection artifacts." >> trends_report.txt
        
      working-directory: .
      
    - name: Check if trends report was created
      run: |
        echo "Checking if trends report was created..."
        if [ -f "trends_report.txt" ]; then
          echo "Trends report exists, will upload artifact"
          echo "report-exists=true" >> $GITHUB_OUTPUT
        else
          echo "Trends report does not exist, skipping artifact upload"
          echo "report-exists=false" >> $GITHUB_OUTPUT
        fi
        
    - name: Upload trends report
      if: steps.check-trends-report.outputs.report-exists == 'true'
      uses: actions/upload-artifact@v4
      with:
        name: performance-trends-report
        path: trends_report.txt
        retention-days: 90
